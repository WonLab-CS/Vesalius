% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/map_assays.R
\name{map_assays}
\alias{map_assays}
\title{Aling and integrate spatial assay from the same modality using super pixels}
\usage{
map_assays(
  seed_assay,
  query_assay,
  signal = "variable_features",
  use_cost = c("feature", "niche"),
  method = "pearson",
  neighborhood = "knn",
  k = 20,
  radius = 0.05,
  depth = 1,
  dimensions = seq(1, 30),
  batch_size = 10000,
  epochs = 1,
  allow_duplicates = TRUE,
  threshold = 0.3,
  filter_cells = FALSE,
  use_norm = "raw",
  scale = FALSE,
  custom_cost = NULL,
  seed_territory_labels = "Territory",
  query_territory_labels = "Territory",
  seed_meta_labels = NULL,
  query_meta_labels = NULL,
  jitter = 0,
  digits = 5,
  verbose = TRUE
)
}
\arguments{
\item{seed_assay}{vesalius_assay object - data to be mapped to}

\item{query_assay}{vesalius_assay objecy - data to map}

\item{signal}{character (variable_features, all_features, embeddings, custom)
- What should  be used as cell signal to generate the cost matrix.
Seed details}

\item{use_cost}{character string defining how should total cost be computer
Available: feature, niche, territory, composition, cell_type (See details for combinations
and custom matrices)}

\item{method}{character - which pearson correlation to use? 
(pearson, pearson_fast, pearson_exact) TO BE DEPRECIATED}

\item{neighborhood}{character - how should the neighborhood be selected?
"knn", "radius", "graph"}

\item{k}{int ]2, n_points] number of neareset neighbors to be considered for
neighborhodd computation.}

\item{radius}{numeric ]0,1[ proportion of max distance between points 
to consider for the neighborhood}

\item{depth}{int [1, NA] graph depth from cell to consider from neighborhood
(See details)}

\item{dimensions}{Int vector containing latent space dimensions to use}

\item{batch_size}{number of points per batch in query during assignment
problem solving}

\item{epochs}{int [1, [ - Across how many epochs should the mapping occur?
Note that if batch_size is larger than both data sets, running across epochs
will not improve mapping.}

\item{allow_duplicates}{logical - Should duplicated barcodes be retained? If FALSE
then match with lowest cost will be retainined.}

\item{threshold}{numeric - Any cell (accros all matrices except cell_type) whose max score
falls below this threshold will be removed.}

\item{filter_cells}{logical - If cell_type cost matrix is requested, remove cells from
query that are not present in the seed data set.}

\item{use_norm}{character - which count data to use (default = "raw")}

\item{scale}{logical - should signal be scaled?}

\item{custom_cost}{list - list of matrices of size n (query cells) by p (seed cells)
containing custom cost matrix. List elements should be named and called for in use_cost.}

\item{seed_territory_labels}{character - name of column in seed containing territories
which should be used for territory cost}

\item{query_territory_labels}{character - name of column in query containing territories
which should be used for territory cost}

\item{seed_meta_labels}{character - name of columns in seed containing meta information
to be parse to the mapped object. First name will be used for cell_type cost if
requested.}

\item{query_meta_labels}{character - name of columns in query containing meta information
to be parse to the mapped object. First name will be used for cell_type cost if
requested.}

\item{digits}{number of digits to retain after computing correlation. More digits
equals to a more precise mapping but significantly increase run time.}

\item{verbose}{logical - should I be a noisy boy?}
}
\value{
vesalius_assay with mapped coordinates
}
\description{
Aling and integrate spatial assay from the same modality using super pixels
}
\details{
The goal is to assign the best matching point between a seed set and
a query set.

To do so, \code{map_assays} will first extract a
biological signal. This can be latent space embeddings per cell, or by using
gene counts (or any other modality).

If using gene counts, there are a few more options available to
you. First, you can select "variable_features" and vesalius will find the
intersection between the variable features in your seed_assay and your
query_assay. "all_features" will find the intersection of all genes across
assays (even if they are not highly variable). Finally, you can also select
a custom gene vector, containing only the gene set you are interested in.

The second step is to create a cost matrix. The creation of a cost matrix
is achieved by pair-wise sum of various cost matrices. By default, 
the map_assays function will use "feature" and "niche" cost matrices. 
The feature matrix computes the pearson correlation between the seed and query
using which ever signal was defined by the signal argument (variable_features)
will compute the correlation between shared variable features in seed 
and query).
The niche matrix will be computed by using the pearson correlation between
niche expression profiles (based on signal). Niche are defined using the
neighborhood argument where knn represent the k nearest neighbors algorithm
(with k defining the number of nearest neighbors), depth represents the 
graph depth of a local neighborhood graph, and radius defining a spatial
radius surrunding a center cell. The singal (expression or embedding) is
average across all cells in the niche.
The territory matrix will compare the average signal of vesalius 
territories between seed and query. 
The composition matrix will compute a frequency aware jaccard index
between cell types present in a niche. Cell types must be assigned 
to seed and query vesalius objects  (See add_cells function)
cell_type cost matrix will check cell labels. If they are the same 
the cell pair receives a score of 1 otherwise 0.
Total cost matrix will be computed by computing the pairwise sum 
of the complement (1 - p ) of each cost matrix. 

This cost matrix is then parsed to a LAPVJ algorithm that will 
generate point pairs that minimize the overall cost. 

To improve run time, cost matrices are split into random batches where each cell
will be selected at least once for mapping. At each epoch a new random batch
will be selected and the mapping pair with the lowest cost will be retained.
}
\examples{
\dontrun{
data(vesalius)
# Create Vesalius object for processing
vesalius <- build_vesalius_assay(coordinates, counts)
jitter_ves <- build_vesalius_assay(jitter_coord, jitter_counts)
mapped <- map_assays(vesalius, jitter_ves)
}
}
